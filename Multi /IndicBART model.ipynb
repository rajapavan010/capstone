{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c76e7b86",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.3.2 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
      "\n",
      "[notice] A new release of pip is available: 23.3.2 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
      "\n",
      "[notice] A new release of pip is available: 23.3.2 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
      "\n",
      "[notice] A new release of pip is available: 23.3.2 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
      "\n",
      "[notice] A new release of pip is available: 23.3.2 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install --quiet transformers\n",
    "!pip install --quiet sentencepiece\n",
    "!pip install --quiet datasets\n",
    "!pip install --quiet rouge_score\n",
    "! pip install --quiet  evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bfbb5d69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14000, 5)\n",
      "                       id                                                url  \\\n",
      "0  international-53649907  https://www.bbc.com/telugu/international-53649907   \n",
      "1          india-46550604          https://www.bbc.com/telugu/india-46550604   \n",
      "2          india-43404438          https://www.bbc.com/telugu/india-43404438   \n",
      "3  international-54671956  https://www.bbc.com/telugu/international-54671956   \n",
      "4                53723894                https://www.bbc.com/telugu/53723894   \n",
      "\n",
      "                                               title  \\\n",
      "0  పాకిస్తాన్ ఎయిర్‌లైన్స్‌లో నకిలీ లైసెన్సుల పైల...   \n",
      "1  తెలంగాణ ముఖ్యమంత్రిగా కేసీఆర్ రెండోసారి ప్రమాణ...   \n",
      "2  ‘అధికారం కొన్ని కులాల గుప్పిట్లోనే ఉండాలా? కుద...   \n",
      "3  పోలండ్‌లో కొత్త అబార్షన్ చట్టాలను వ్యతిరేకిస్త...   \n",
      "4  దిల్లీ అల్లర్లపై పరస్పర విరుద్ధ నివేదికలు... ఏ...   \n",
      "\n",
      "                                             summary  \\\n",
      "0  పాకిస్తాన్ విమానయాన రంగంలో కొత్త సంక్షోభం మొదల...   \n",
      "1  తెలంగాణ ముఖ్యమంత్రిగా కల్వకుంట్ల చంద్రశేఖర్ రా...   \n",
      "2  గుంటూరులో జనసేన ఆవిర్భావ దినోత్సవ సభ జరిగింది....   \n",
      "3  పోలండ్‌లోని కొత్త అబార్షన్ చట్టాలకు వ్యతిరేకంగ...   \n",
      "4  ఈ ఏడాది ఫిబ్రవరిలో జరిగిన ఢిల్లీ హింసలో ఏ వర్గ...   \n",
      "\n",
      "                                                text  \n",
      "0  అయితే, ఆ జాబితా తప్పులతడకని పైలట్లు అంటున్నారు...  \n",
      "1  ఆ తరువాత ఆయన రెండోసారి ముఖ్యమంత్రిగా బాధ్యతలు ...  \n",
      "2  ప్రత్యేక హోదా సాధన, టీడీపీపై విమర్శలే ప్రధానాస...  \n",
      "3  గత ఏడాది చట్టబద్ధంగా జరిగిన అబార్షన్లలో 98% కడ...  \n",
      "4  అయితే, ఈ అంశంపై సొంతంగా విచారణ జరిపిన ఈ కమిటీల...  \n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "\n",
    "languages = [\"telugu\", \"urdu\", \"marathi\", \"hindi\", \"tamil\", \"bengali\", \"english\"]\n",
    "\n",
    "dfs = []\n",
    "for lang in languages:\n",
    "    dataset = load_dataset(\"csebuetnlp/xlsum\", lang, split=\"train[:2000]\")\n",
    "    df = dataset.to_pandas()\n",
    "    dfs.append(df)\n",
    "\n",
    "df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "print(df.shape)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6cfaa578",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SRMAPCSELAB2022-147\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\utils\\_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "from transformers import AdamW, get_scheduler\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import seaborn as sns\n",
    "from pylab import rcParams\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rc\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "import evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f07bd641",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"ai4bharat/IndicBART-XLSum\")\n",
    "\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"ai4bharat/IndicBART-XLSum\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a3890e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SummaryDataset(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        data=df,\n",
    "        tokenizer=tokenizer,\n",
    "        text_max_token_len = 200,\n",
    "        summary_max_token_len = 12\n",
    "    ):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.data = data\n",
    "        self.text_max_token_len = text_max_token_len\n",
    "        self.summary_max_token_len = summary_max_token_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index: int):\n",
    "        data_row = self.data.iloc[index]\n",
    "\n",
    "        text = data_row['text']\n",
    "\n",
    "        text_encoding = tokenizer(\n",
    "            text,\n",
    "            max_length=self.text_max_token_len,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "            add_special_tokens=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "\n",
    "        summary_encoding = tokenizer(\n",
    "            data_row['summary'],\n",
    "            max_length=self.summary_max_token_len,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "            add_special_tokens=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "\n",
    "        labels = summary_encoding['input_ids']\n",
    "        labels[labels == tokenizer.pad_token_id] = -100\n",
    "\n",
    "        return dict(\n",
    "            input_ids=text_encoding['input_ids'].flatten(),\n",
    "            attention_mask=text_encoding['attention_mask'].flatten(),\n",
    "            labels=labels.flatten(),\n",
    "            decoder_attention_mask=summary_encoding['attention_mask'].flatten()\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c780c7ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_test = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "train_dataset = SummaryDataset(data=df_train)\n",
    "test_dataset = SummaryDataset(data=df_test)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, shuffle=True, batch_size=10)\n",
    "eval_dataloader = DataLoader(test_dataset, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3957f4c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5adb213e7ca74ee9af31abf683a37ec6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 -- loss: 2.5620110034942627\n",
      "epoch: 2 -- loss: 3.335263729095459\n",
      "epoch: 3 -- loss: 2.803818941116333\n",
      "epoch: 4 -- loss: 2.3650505542755127\n",
      "epoch: 5 -- loss: 1.9573122262954712\n",
      "epoch: 6 -- loss: 1.6121840476989746\n",
      "epoch: 7 -- loss: 1.389049768447876\n",
      "epoch: 8 -- loss: 1.1359344720840454\n",
      "epoch: 9 -- loss: 1.1917107105255127\n",
      "epoch: 10 -- loss: 0.8483394980430603\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "\n",
    "num_training_steps = num_epochs * len(train_dataloader)\n",
    "\n",
    "optimizer = AdamW(model.parameters())\n",
    "lr_scheduler = get_scheduler(\n",
    "    \"linear\",\n",
    "    optimizer=optimizer,\n",
    "    num_warmup_steps=0,\n",
    "    num_training_steps=num_training_steps\n",
    ")\n",
    "\n",
    "progress_bar = tqdm(range(num_training_steps))\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "model.train()\n",
    "for epoch in range(num_epochs):\n",
    "    for batch in train_dataloader:\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "\n",
    "        outputs = model(**batch)\n",
    "#         logits = outputs.logits\n",
    "#         predictions = torch.argmax(logits, dim=-1)\n",
    "#         print(predictions)\n",
    "#         print(batch[\"labels\"])\n",
    "\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        progress_bar.update()\n",
    "\n",
    "    torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'loss': loss, +\n",
    "            }, f'./IndicBART-multi.pth')\n",
    "\n",
    "    print(f'epoch: {epoch + 1} -- loss: {loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d2737ee4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROUGE Score: {'rouge1': 0.88529956485129, 'rouge2': 0.764345452749864, 'rougeL': 0.8845272393954617, 'rougeLsum': 0.8847436248461508}\n",
      "BLEU Score: {'bleu': 0.2305442936045835, 'precisions': [0.595922012204197, 0.413606104887157, 0.24472227183425613, 0.04683468942250447], 'brevity_penalty': 1.0, 'length_ratio': 1.004905626514313, 'translation_length': 33595, 'reference_length': 33431}\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import evaluate\n",
    "\n",
    "rouge = evaluate.load(\"rouge\")\n",
    "bleu = evaluate.load(\"bleu\")\n",
    "\n",
    "model.eval()\n",
    "\n",
    "all_predictions = []\n",
    "all_references = []\n",
    "\n",
    "for batch in eval_dataloader:\n",
    "    batch = {k: v.to(device) for k, v in batch.items()}\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**batch)\n",
    "\n",
    "    logits = outputs.logits\n",
    "    predictions = torch.argmax(logits, dim=-1)\n",
    "\n",
    "    decoded_predictions = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
    "\n",
    "    # Replace -100 with pad_token_id before decoding\n",
    "    labels = batch[\"labels\"]\n",
    "    labels[labels == -100] = tokenizer.pad_token_id\n",
    "\n",
    "    decoded_references = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "\n",
    "    all_predictions.extend(decoded_predictions)\n",
    "    all_references.extend(decoded_references)\n",
    "\n",
    "rouge_score = rouge.compute(predictions=all_predictions, references=all_references)\n",
    "bleu_score = bleu.compute(predictions=all_predictions, references=all_references)\n",
    "\n",
    "print(\"ROUGE Score:\", rouge_score)\n",
    "print(\"BLEU Score:\", bleu_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b36ea866",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
